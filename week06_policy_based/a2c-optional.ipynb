{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in google colab uncomment this\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.system('apt-get install -y xvfb')\n",
    "# os.system('wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb -O ../xvfb')\n",
    "# os.system('apt-get install -y python-opengl ffmpeg')\n",
    "# os.system('pip install pyglet==1.2.4')\n",
    "\n",
    "# os.system('python -m pip install -U pygame --user')\n",
    "\n",
    "# print('setup complete')\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Advantage-Actor Critic (A2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will implement Advantage Actor Critic algorithm that trains on a batch of Atari 2600 environments running in parallel. \n",
    "\n",
    "Firstly, we will use environment wrappers implemented in file `atari_wrappers.py`. These wrappers preprocess observations (resize, grayscal, take max between frames, skip frames and stack them together) and rewards. Some of the wrappers help to reset the environment and pass `done` flag equal to `True` when agent dies.\n",
    "File `env_batch.py` includes implementation of `ParallelEnvBatch` class that allows to run multiple environments in parallel. To create an environment we can use `nature_dqn_env` function. Note that if you are using \n",
    "PyTorch and not using `tensorboardX` you will need to implement a wrapper that will log **raw** total rewards that the *unwrapped* environment returns and redefine the implemention of `nature_dqn_env` function here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n",
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n",
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n",
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n",
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point is :gym.envs.atari:AtariEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(require = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<env_batch.SpaceBatch object at 0x7f224a5546a0>\n",
      "[4 5 0 3 3 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from atari_wrappers import nature_dqn_env\n",
    "\n",
    "\n",
    "env = nature_dqn_env(\"SpaceInvadersNoFrameskip-v4\", nenvs=8)\n",
    "obs = env.reset()\n",
    "assert obs.shape == (8, 84, 84, 4) # 8 个环境并行，84x84单色，4帧合并 \n",
    "assert obs.dtype == np.uint8\n",
    "print(env.action_space) # Discrete(6) 0-5\n",
    "print(env.action_space.sample()) # 8 个环境并行 ,每个连续按动同一个动作 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to implement a model that predicts logits and values. It is suggested that you use the same model as in [Nature DQN paper](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf) with a modification that instead of having a single output layer, it will have two output layers taking as input the output of the last hidden layer. **Note** that this model is different from the model you used in homework where you implemented DQN. You can use your favorite deep learning framework here. We suggest that you use orthogonal initialization with parameter $\\sqrt{2}$ for kernels and initialize biases with zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model_class(\n",
      "  (net): HybridSequential(\n",
      "    (0): Conv2D(None -> 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2D(None -> 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (3): Conv2D(None -> 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): Conv2D(None -> 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=avg, layout=NCHW)\n",
      "  )\n",
      "  (actions_conv2d): Conv2D(None -> 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (actions_desen): Dense(None -> 6, Activation(relu))\n",
      "  (values_conv2d): Conv2D(None -> 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (values_desen): Dense(None -> 1, Activation(sigmoid))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as torch\n",
    "# import torch as tf\n",
    "import mxnet as mx\n",
    "# <Define your model here>\n",
    "class my_model_class(mx.gluon.nn.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(my_model_class, self).__init__(**kwargs)\n",
    "        self.net = mx.gluon.nn.HybridSequential()\n",
    "        self.net.add(mx.gluon.nn.Conv2D(channels=4,layout=\"NCHW\",kernel_size=3))\n",
    "        self.net.add(mx.gluon.nn.Conv2D(channels=16,layout=\"NCHW\",kernel_size=3))\n",
    "        self.net.add(mx.gluon.nn.Conv2D(channels=16,layout=\"NCHW\",kernel_size=2))\n",
    "        self.net.add(mx.gluon.nn.Conv2D(channels=8,layout=\"NCHW\",kernel_size=2))\n",
    "        self.net.add(mx.gluon.nn.Conv2D(channels=4,layout=\"NCHW\",kernel_size=3))\n",
    "        self.net.add(mx.gluon.nn.AvgPool2D(layout=\"NCHW\",pool_size=2))\n",
    "        #\n",
    "        self.actions_conv2d = mx.gluon.nn.Conv2D(channels=1,layout=\"NCHW\",kernel_size=3)\n",
    "        self.actions_desen = mx.gluon.nn.Dense(6,activation='relu')\n",
    "        #\n",
    "        self.values_conv2d = mx.gluon.nn.Conv2D(channels=1,layout=\"NCHW\",kernel_size=3)\n",
    "        self.values_desen = mx.gluon.nn.Dense(1,activation='sigmoid')\n",
    "    def hybrid_forward(self,F,x):\n",
    "        middle_x = self.net(x)\n",
    "        y_actions = self.actions_conv2d(middle_x)\n",
    "        y_actions = self.actions_desen(y_actions)\n",
    "        y_values = self.values_conv2d(middle_x)\n",
    "        y_values = self.values_desen(y_values)\n",
    "        return y_actions, y_values\n",
    "\n",
    "model = my_model_class()\n",
    "print(model)\n",
    "model.initialize(init=mx.init.Xavier())\n",
    "model.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to define and use a policy that wraps the model. While the model computes logits for all actions, the policy will sample actions and also compute their log probabilities.  `policy.act` should return a dictionary of all the arrays that are needed to interact with an environment and train the model.\n",
    " Note that actions must be an `np.ndarray` while the other\n",
    "tensors need to have the type determined by your deep learning framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_policy = Policy(model)\\ninputs = mx.nd.random.uniform(low=0, high=255,shape = (8,48,48,4),dtype='float32')\\nprint(inputs.shape)\\nrel = test_policy.act(inputs)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Policy():\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    \n",
    "  def act(self, inputs):\n",
    "    # Implement policy by calling model, sampling actions and computing their log probs>\n",
    "    # Should return a dict containing keys ['actions', 'logits', 'log_probs', 'values'].\n",
    "    # 生成以各种keys名称对应的m=envs行，actions = 1列，logits = 6列，log_probs = 6列，values = 1列的字典\n",
    "    \n",
    "    inputs = mx.nd.array(inputs,dtype = 'float32')\n",
    "    #print(inputs.shape)\n",
    "    inputs = mx.nd.transpose(inputs, axes=(0,3,1,2))\n",
    "    #print('转换后输入x维度：{}'.format(inputs.shape))\n",
    "    y_actions, y_values = self.model(inputs) # y_values 就是 V_hat_t(s_t,theata_v) \n",
    "    #print(y_actions.shape)\n",
    "    #print(y_values.shape)\n",
    "    rel = {}\n",
    "    logits = mx.nd.softmax(y_actions,axis=-1)\n",
    "    #print(logits.shape)\n",
    "    rel['logits'] = logits\n",
    "    m,n = logits.shape\n",
    "    rel['actions'] = []\n",
    "    for i in np.arange(m):\n",
    "        probs = logits[i,:].asnumpy()\n",
    "        #print(probs)\n",
    "        rel['actions'].append(np.random.choice(np.array([0,1,2,3,4,5]),1,p = probs)[0])\n",
    "    #print(rel['actions'])\n",
    "    log_probs = mx.nd.log_softmax(y_actions,axis=-1)\n",
    "    rel['log_probs'] = log_probs\n",
    "    rel['values'] = y_values\n",
    "    return rel\n",
    "'''\n",
    "test_policy = Policy(model)\n",
    "inputs = mx.nd.random.uniform(low=0, high=255,shape = (8,48,48,4),dtype='float32')\n",
    "print(inputs.shape)\n",
    "rel = test_policy.act(inputs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will pass the environment and policy to a runner that collects partial trajectories from the environment. \n",
    "The class that does is is already implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runners import EnvRunner\n",
    "# 这个运行程序与环境交互一定数量的步骤，并返回一个包含键的字典\n",
    "# 在每个键下面都有一个python列表，其中列出了与指定长度T（部分轨迹的大小）的环境的交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runner interacts with the environment for a given number of steps and returns a dictionary containing\n",
    "keys \n",
    "\n",
    "* 'observations' \n",
    "* 'rewards' \n",
    "* 'resets'\n",
    "* 'actions'\n",
    "* all other keys that you defined in `Policy`\n",
    "\n",
    "under each of these keys there is a python `list` of interactions with the environment of specified length $T$ &mdash; the size of partial trajectory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the part of the model that predicts state values you will need to compute the value targets. \n",
    "Any callable could be passed to `EnvRunner` to be applied to each partial trajectory after it is collected. \n",
    "Thus, we can implement and use `ComputeValueTargets` callable. \n",
    "The formula for the value targets is simple:\n",
    "\n",
    "$$\n",
    "\\hat v(s_t) = \\sum_{t'=0}^{T - 1}\\gamma^{t'}r_{t+t'} + \\gamma^T \\hat{v}(s_{t+T}),\n",
    "$$\n",
    "\n",
    "In implementation, however, do not forget to use \n",
    "`trajectory['resets']` flags to check if you need to add the value targets at the next step when \n",
    "computing value targets for the current step. You can access `trajectory['state']['latest_observation']`\n",
    "to get last observations in partial trajectory &mdash; $s_{t+T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 训练角色对于预测状态值的模型，您将需要计算值目标。任何可调用的都可以传递给EnvRunner，\n",
    "# 以便在收集后应用于每个部分轨迹。因此，我们可以实现和使用ComputeValueTargets callable。\n",
    "# 价值目标的公式很简单\n",
    "class ComputeValueTargets():\n",
    "  def __init__(self, policy, gamma=0.99):\n",
    "    self.policy = policy\n",
    "    self.gamma = gamma\n",
    "  def __call__(self, trajectory):\n",
    "    # This method should modify trajectory inplace by adding \n",
    "    # an item with key 'value_targets' to it. \n",
    "    # <Compute value targets for a given partial trajectory>\n",
    "    \n",
    "    # get traectory message\n",
    "    T = len(trajectory['rewards'])\n",
    "    v_hat_s_t = []\n",
    "    for t in range(T):\n",
    "        #print(t)\n",
    "        #print(trajectory['resets'][t])\n",
    "        one_step_v_hat_s_t = []\n",
    "        for env_n in range(len(trajectory['resets'][t])):\n",
    "            #print(env_n)\n",
    "            v_hat_s_t_env_n = 0\n",
    "            if trajectory['resets'][t][env_n]:\n",
    "                pass\n",
    "            else:\n",
    "                # sum to T\n",
    "                for t_pi in range(t,T):\n",
    "                    if trajectory['resets'][t_pi][env_n]:\n",
    "                        pass\n",
    "                    else:\n",
    "                        # 获得v_hat_s_tT\n",
    "                        predict_dict = self.policy.act(trajectory['state']['latest_observation'])\n",
    "                        v_hat_s_tT = predict_dict['values'][env_n]\n",
    "                        #print(v_hat_s_tT)\n",
    "                        v_hat_s_t_env_n += self.gamma ** t_pi * trajectory['rewards'][t_pi][env_n] + self.gamma ** T *  v_hat_s_tT\n",
    "            one_step_v_hat_s_t.append(v_hat_s_t_env_n.asscalar())\n",
    "        v_hat_s_t.append(one_step_v_hat_s_t)\n",
    "    trajectory['value_targets'] = v_hat_s_t\n",
    "    return trajectory    \n",
    "#test = ComputeValueTargets(policy = [1,2,3])\n",
    "#rel['rewards'] = [i for i in range(len(rel))]\n",
    "#print(test(rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing value targets we will transform lists of interactions into tensors\n",
    "with the first dimension `batch_size` which is equal to `T * nenvs`, i.e. you essentially need\n",
    "to flatten the first two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在计算了价值目标之后，我们将把交互列表转换成第一维度的张量，\n",
    "# 其大小等于T=5 * nenvs=8，也就是说，你基本上需要展平前两个维度。\n",
    "class MergeTimeBatch:\n",
    "  \"\"\" Merges first two axes typically representing time and env batch. \"\"\"\n",
    "  def __call__(self, trajectory):\n",
    "    # Modify trajectory inplace. \n",
    "    # <TODO: implement>\n",
    "    # T行一组，每个环境顺次连排\n",
    "    \n",
    "    for key in list(trajectory.keys()):\n",
    "        print('变量名称：{}'.format(key))\n",
    "        #print(type(trajectory[key]))\n",
    "        #print(trajectory[key])\n",
    "        if key == 'observations':\n",
    "            #print(len(trajectory[key]))\n",
    "            trajectory[key] = np.concatenate(trajectory[key], axis = 0)\n",
    "            print('处理后维度:{}'.format(trajectory[key].shape))\n",
    "        elif isinstance(trajectory[key], list):\n",
    "            temp_var = []\n",
    "            for element in trajectory[key]:\n",
    "                if isinstance(element, list):\n",
    "                    temp_var.extend(element)\n",
    "                elif isinstance(element, np.ndarray):\n",
    "                    temp_var.extend(element.tolist())\n",
    "                elif isinstance(element, mx.nd.NDArray):\n",
    "                    temp_var.extend(element.asnumpy().tolist())\n",
    "            trajectory[key] = np.asarray(temp_var)\n",
    "            print('处理后维度:{}'.format(trajectory[key].shape))\n",
    "        elif isinstance(trajectory[key], dict):\n",
    "            #print('dict')\n",
    "            pass\n",
    "    return trajectory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n",
      "{'action': [1, 2, 3]}\n",
      "dict_items([('action', [1, 2, 3])])\n",
      "dict_keys(['action'])\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "a = defaultdict(list, {\"actions\": []})\n",
    "print(type(a))\n",
    "b = dict()\n",
    "b['action'] = [1,2,3]\n",
    "print(b)\n",
    "print(b.items())\n",
    "print(b.keys())\n",
    "print(b['action'])\n",
    "np.all([False,False])\n",
    "np.std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "变量名称：actions\n",
      "处理后维度:(40,)\n",
      "变量名称：logits\n",
      "处理后维度:(40, 6)\n",
      "变量名称：log_probs\n",
      "处理后维度:(40, 6)\n",
      "变量名称：values\n",
      "处理后维度:(40, 1)\n",
      "变量名称：observations\n",
      "处理后维度:(40, 84, 84, 4)\n",
      "变量名称：rewards\n",
      "处理后维度:(40,)\n",
      "变量名称：resets\n",
      "处理后维度:(40,)\n",
      "变量名称：state\n",
      "变量名称：value_targets\n",
      "处理后维度:(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'actions': array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]),\n",
       "             'logits': array([[3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003075e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34666827e-16],\n",
       "                    [3.32345242e-30, 1.07003489e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34664021e-16],\n",
       "                    [3.32345242e-30, 1.07003489e-24, 3.32345242e-30, 1.00000000e+00,\n",
       "                     3.32345242e-30, 7.34664021e-16],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86590038e-30, 2.05318859e-24, 6.86590038e-30, 1.00000000e+00,\n",
       "                     6.86590038e-30, 1.23867557e-15],\n",
       "                    [6.86584772e-30, 2.05318859e-24, 6.86584772e-30, 1.00000000e+00,\n",
       "                     6.86584772e-30, 1.23866149e-15],\n",
       "                    [6.86584772e-30, 2.05318859e-24, 6.86584772e-30, 1.00000000e+00,\n",
       "                     6.86584772e-30, 1.23866149e-15],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02976080e-28, 2.56702937e-22, 3.02976080e-28, 1.00000000e+00,\n",
       "                     3.02976080e-28, 1.05148358e-14],\n",
       "                    [3.02974901e-28, 2.56701952e-22, 3.02974901e-28, 1.00000000e+00,\n",
       "                     3.02974901e-28, 1.05147155e-14],\n",
       "                    [3.02974901e-28, 2.56701952e-22, 3.02974901e-28, 1.00000000e+00,\n",
       "                     3.02974901e-28, 1.05147155e-14],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06431028e-30, 9.25505182e-24, 7.06431028e-30, 1.00000000e+00,\n",
       "                     7.06431028e-30, 2.49288509e-15],\n",
       "                    [7.06425612e-30, 9.25498083e-24, 7.06425612e-30, 1.00000000e+00,\n",
       "                     7.06425612e-30, 2.49287577e-15],\n",
       "                    [7.06425612e-30, 9.25498083e-24, 7.06425612e-30, 1.00000000e+00,\n",
       "                     7.06425612e-30, 2.49287577e-15],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973101e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82828707e-13],\n",
       "                    [8.06170020e-29, 1.29973598e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82824262e-13],\n",
       "                    [8.06170020e-29, 1.29973598e-23, 8.06170020e-29, 1.00000000e+00,\n",
       "                     8.06170020e-29, 5.82824262e-13]]),\n",
       "             'log_probs': array([[-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.19435501, -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711456],\n",
       "                    [-67.87654877, -55.1943512 , -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711838],\n",
       "                    [-67.87654877, -55.1943512 , -67.87654877,   0.        ,\n",
       "                     -67.87654877, -34.84711838],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15098572, -54.54264832, -67.15098572,   0.        ,\n",
       "                     -67.15098572, -34.32473373],\n",
       "                    [-67.15099335, -54.54264832, -67.15099335,   0.        ,\n",
       "                     -67.15099335, -34.32474518],\n",
       "                    [-67.15099335, -54.54264832, -67.15099335,   0.        ,\n",
       "                     -67.15099335, -34.32474518],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36389923, -49.71412277, -63.36389923,   0.        ,\n",
       "                     -63.36389923, -32.18598938],\n",
       "                    [-63.36390305, -49.71412659, -63.36390305,   0.        ,\n",
       "                     -63.36390305, -32.18600082],\n",
       "                    [-63.36390305, -49.71412659, -63.36390305,   0.        ,\n",
       "                     -63.36390305, -32.18600082],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12249756, -53.03687286, -67.12249756,   0.        ,\n",
       "                     -67.12249756, -33.62533569],\n",
       "                    [-67.12250519, -53.03688049, -67.12250519,   0.        ,\n",
       "                     -67.12250519, -33.62533951],\n",
       "                    [-67.12250519, -53.03688049, -67.12250519,   0.        ,\n",
       "                     -67.12250519, -33.62533951],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729996, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17088318],\n",
       "                    [-64.68784332, -52.69729614, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17089081],\n",
       "                    [-64.68784332, -52.69729614, -64.68784332,   0.        ,\n",
       "                     -64.68784332, -28.17089081]]),\n",
       "             'values': array([[1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.],\n",
       "                    [1.]]),\n",
       "             'observations': array([[[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]],\n",
       "             \n",
       "             \n",
       "                    [[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]],\n",
       "             \n",
       "             \n",
       "                    [[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]],\n",
       "             \n",
       "             \n",
       "                    ...,\n",
       "             \n",
       "             \n",
       "                    [[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]],\n",
       "             \n",
       "             \n",
       "                    [[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]],\n",
       "             \n",
       "             \n",
       "                    [[[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     [[ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      ...,\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0],\n",
       "                      [ 0,  0,  0,  0]],\n",
       "             \n",
       "                     ...,\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]],\n",
       "             \n",
       "                     [[79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      ...,\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79],\n",
       "                      [79, 79, 79, 79]]]], dtype=uint8),\n",
       "             'rewards': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                    0., 0., 0., 0., 0., 0.]),\n",
       "             'resets': array([False, False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False]),\n",
       "             'state': {'latest_observation': array([[[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]],\n",
       "              \n",
       "              \n",
       "                     [[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]],\n",
       "              \n",
       "              \n",
       "                     [[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]],\n",
       "              \n",
       "              \n",
       "                     ...,\n",
       "              \n",
       "              \n",
       "                     [[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]],\n",
       "              \n",
       "              \n",
       "                     [[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]],\n",
       "              \n",
       "              \n",
       "                     [[[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      [[ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       ...,\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0],\n",
       "                       [ 0,  0,  0,  0]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]],\n",
       "              \n",
       "                      [[79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       ...,\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79],\n",
       "                       [79, 79, 79, 79]]]], dtype=uint8), 'env_steps': 5},\n",
       "             'value_targets': array([4.75495  , 4.75495  , 4.75495  , 4.75495  , 4.75495  , 4.75495  ,\n",
       "                    4.75495  , 4.75495  , 3.80396  , 3.80396  , 3.80396  , 3.80396  ,\n",
       "                    3.80396  , 3.80396  , 3.80396  , 3.80396  , 2.8529701, 2.8529701,\n",
       "                    2.8529701, 2.8529701, 2.8529701, 2.8529701, 2.8529701, 2.8529701,\n",
       "                    1.90198  , 1.90198  , 1.90198  , 1.90198  , 1.90198  , 1.90198  ,\n",
       "                    1.90198  , 1.90198  , 0.95099  , 0.95099  , 0.95099  , 0.95099  ,\n",
       "                    0.95099  , 0.95099  , 0.95099  , 0.95099  ], dtype=float32)})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model     # <Create your model here>\n",
    "policy_obj = Policy(model)\n",
    "runner = EnvRunner(env = env, policy = policy_obj, nsteps=5, transforms=[ComputeValueTargets(policy_obj),MergeTimeBatch()])\n",
    "runner.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the time to implement the advantage actor critic algorithm itself. You can look into your lecture,\n",
    "[Mnih et al. 2016](https://arxiv.org/abs/1602.01783) paper, and [lecture](https://www.youtube.com/watch?v=Tol_jw5hWnI&list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37&index=20) by Sergey Levine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class A2C:\n",
    "    def __init__(self,\n",
    "               policy,\n",
    "               optimizer,\n",
    "               value_loss_coef=0.25,\n",
    "               entropy_coef=0.01,\n",
    "               max_grad_norm=0.5):\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.value_loss_coef = value_loss_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.max_grad_norm = max_grad_norm   \n",
    "    def policy_loss(self, trajectory):\n",
    "        # You will need to compute advantages here. \n",
    "        # <TODO: implement>\n",
    "        adv = trajectory['value_targets'].reshape((-1,1)) - trajectory['values']\n",
    "        print(adv.shape)    # 40xn_a\n",
    "        return np.sum(adv * trajectory['log_probs'], axis = 1)   # 40xn_a\n",
    "    def value_loss(self, trajectory):\n",
    "        # <TODO: implement>\n",
    "        loss_v = 1/2 * np.sum(np.square(trajectory['value'] - trajectory['rewards'].reshape((-1,1))), axis = 1)\n",
    "        return loss_v # 40xn_a\n",
    "    def loss(self, trajectory):\n",
    "        # <TODO: implement>\n",
    "        pi_s_a = -1 * mx.nd.one_hot(trajectory['actions'], trajectory['logits'].shape[-1])\n",
    "        loss_all = -mx.nd.mean(self.policy_loss(trajectory) + self.value_loss(trajectory) + pi_s_a, axis = 1)\n",
    "        return loss_all\n",
    "    def step(self, trajectory):\n",
    "        # <TODO: implement>\n",
    "        # 得到环境轨迹记录\n",
    "        \n",
    "        # 训练theata_pi,theata_v\n",
    "        \n",
    "        \n",
    "        # \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train your model. With reasonable hyperparameters training on a single GTX1080 for 10 million steps across all batched environments (which translates to about 5 hours of wall clock time)\n",
    "it should be possible to achieve *average raw reward over last 100 episodes* (the average is taken over 100 last \n",
    "episodes in each environment in the batch) of about 600. You should plot this quantity with respect to \n",
    "`runner.step_var` &mdash; the number of interactions with all environments. It is highly \n",
    "encouraged to also provide plots of the following quantities (these are useful for debugging as well):\n",
    "\n",
    "* [Coefficient of Determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) between \n",
    "value targets and value predictions\n",
    "* Entropy of the policy $\\pi$\n",
    "* Value loss\n",
    "* Policy loss\n",
    "* Value targets\n",
    "* Value predictions\n",
    "* Gradient norm\n",
    "* Advantages\n",
    "* A2C loss\n",
    "\n",
    "For optimization we suggest you use RMSProp with learning rate starting from 7e-4 and linearly decayed to 0, smoothing constant (alpha in PyTorch and decay in TensorFlow) equal to 0.99 and epsilon equal to 1e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c = <Create instance of the algorithm> \n",
    "\n",
    "<Write your training loop>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
